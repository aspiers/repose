<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book [
        <!-- product name is likely to change; parameterize full name, abbreviated name, expanded name -->
        <!ENTITY PRODNAME "Repose">
        <!ENTITY PRODABBREV "Repose">
        <!ENTITY PRODEXPAND "REstful PrOxy Service Engine">
        <!-- Some useful entities borrowed from HTML -->
        <!ENTITY ndash  "&#x2013;">
        <!ENTITY mdash  "&#x2014;">
        <!ENTITY hellip "&#x2026;">

        <!-- Useful for describing APIs -->
        <!ENTITY GET    '<command xmlns="http://docbook.org/ns/docbook">GET</command>'>
        <!ENTITY PUT    '<command xmlns="http://docbook.org/ns/docbook">PUT</command>'>
        <!ENTITY POST   '<command xmlns="http://docbook.org/ns/docbook">POST</command>'>
        <!ENTITY DELETE '<command xmlns="http://docbook.org/ns/docbook">DELETE</command>'>

        <!ENTITY CHECK  '<inlinemediaobject xmlns="http://docbook.org/ns/docbook">
        <imageobject>
        <imagedata fileref="img/Check_mark_23x20_02.svg"
        format="SVG" scale="60"/>
        </imageobject>
        </inlinemediaobject>'>

        <!ENTITY ARROW  '<inlinemediaobject xmlns="http://docbook.org/ns/docbook">
        <imageobject>
        <imagedata fileref="img/Arrow_east.svg"
        format="SVG" scale="60"/>
        </imageobject>
        </inlinemediaobject>'>
        ]>

<section xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:db="http://docbook.org/ns/docbook"
         version="5.0"
         xmlns="http://docbook.org/ns/docbook"


         xml:id="Dist-Datastore-Svc-Chapter">
    <title>Distributed Datastore Service</title>


    <section xml:id="Dist-Datastore-Svc-Introduction">
        <title>Introduction</title>
        <para>Repose uses one of two datastore implementations to store various types of data. The two datastore
            implementations are:
        </para>
        <para>
            <itemizedlist>
                <listitem>
                    <para><link
                            xlink:href="https://repose.atlassian.net/wiki/display/REPOSE/Datastores#Datastores-local"
                            >Local Datastore</link> (name: <emphasis
                            role="bold"
                            >local/default</emphasis>)
                    </para>
                </listitem>
                <listitem>
                    <para>
                        <link
                                xlink:href="https://repose.atlassian.net/wiki/display/REPOSE/Datastores#Datastores-distributed"
                                >Distributed Datastore
                        </link>
                         (name: 
                        <emphasis role="bold"
                                >distributed/hash-ring
                        </emphasis>
                        )
                    </para>
                    <db:para>The local datastore is enabled by
                        default.  The distributed datastore is enabled
                        by including the appropriate service into your
                        system model configuration.
                    </db:para>
                </listitem>
            </itemizedlist>
        </para>
    </section>


    <section xml:id="Local-Datastore">
        <title>Local Datastore</title>
        <para>If no other datastores are configured, then Repose will use the local datastore.
            The local datastore will store data using the cache on each node.
            Data will not be shared among the nodes, so each Repose node will have its own copy of the data.
            For example, if using rate limiting with the local datastore, then each node will track its own
            limit information and limit updates will not be shared other nodes.
        </para>
    </section>


    <section xml:id="Distributed-Datastore">
        <title>Distributed Datastore</title>

        <para>A Repose cluster may, at times, need to share
            information between cluster nodes. The Distributed
            Datastore component allows Repose to host a simple
            hash-ring object store that shares consistency between all
            of the participating cluster nodes. This, in turn, allows
            other hosted components as well as external programs to
            use the Repose cluster as a whole to store
            information.
        </para>
        <para>Instead of cache operations communicating through the Repose Service port (which is the port which Repose
            service requests to pass to the Origin Service), the Distributed Datastore Service will communicate
            through configured port(s) within the distributed datastore configuration. If the
            Distributed Datastore Service is unable to communicate with the service on other nodes,
            it will fall back on the local datastore temporarily. Once other nodes become reachable,
            the Distributed Datastore Service will return to being distributed.
        </para>

    </section>

    <section xml:id="Dist-Datastore-configuration">
        <title>Distributed Datastore Configuration</title>

        <para>Configure the Distributed Datastore service by editing
            the dist-datastore.cfg.xml file. You can add the filter
            to the Repose deployment through the system-model.cfg.xml
            file.
        </para>
        <para>Adding the Distributed Datastore Service to a Repose deployment requires
            that listening ports be configured within the dist-datastore.cfg.xml file.
            The XSD is at dist-datastore-configuration.xsd.
        </para>

        <example>
            <title>Distributed Datastore Example</title>
            <programlisting language="xml">
                <xi:include href="../samples/repose-dist-datastore-example.xml" parse="text"/>
            </programlisting>
        </example>


        <para>The port element is the &lt;port> configuration for the
            Distributed Datastore. When Repose is told to start with
            the Distributed Datastore the running Repose instance will
            try to find the &lt;port> configuration that matches it's
            own cluster and node. If only the 'cluster' attribute is
            defined then the running Repose instance will assume that
            that is the port in which to open a listener for the
            Distributed Datastore.
        </para>


    </section>


    <section xml:id="Dist-Datastore-features">
        <title>Distributed Datastore Features</title>
        <para></para>


        <para>
            <guilabel>Transport</guilabel>
        </para>
        <para>The distributed datastore uses HTTP as its transport protocol.</para>


        <para>
            <guilabel>Key-space Addressing</guilabel>
        </para>
        <para>Addressing a key is done by first normalizing all of
            the participating cluster nodes. This is done by an
            ascending sort. After the participating nodes have had
            their order normalized, the key-space is sliced up by
            dividing the maximum possible number of addresses by
            the total number of participating nodes. The given key
            is then reduced to its numeric representation and a
            cluster node is looked up by performing a modulus such
            that (&lt;key-value> %
            &lt;number-of-cluster-members>).
        </para>


        <section xml:id="Key-space-Encoding">
            <title>Key-space Encoding</title>
            <para>By default, the internal Repose client implementation for the distributed datastore will obscure
                key-space by storing only the MD5 hash value of a given key and not the key's actual value.
                This is important to note since external gets against the distributed datastore must be aware of this
                functionality.
            </para>
            <para>The MD5 hash is represented as a 128bit UUID.</para>

            <!-- Key space encoding example goes here. -->
        </section>

        <section xml:id="Remote-Management">
            <title>Remote Management</title>
            <para>The repose distributed datastore component is a filter component that hosts
                a simple RESTful API that can be contacted to perform remote object store operations.
                These operations are defined below.
            </para>

            <!-- Remote mgt example goes here. -->
        </section>

        <section xml:id="Remote-Fail-Over">
            <title>Remote Fail-Over</title>
            <para>In the event that a node with in a datastore cluster falls off line or is unable to respond to
                requests,
                it is removed from the node's cluster membership for a period of time. During this time, the online node
                will then re-address its key-space in order to continue operation. After certain periods of rest, the
                node
                may attempt to introduce the damaged cluster member into its cluster membership. A damaged cluster
                member
                must go through several validation passes where the member is introduced back into the addressing
                algorithm
                before it can be considered online. In order to keep healthy nodes from attempting to route requests to
                the
                damaged node, a participating node may tell it's destination that the destination may not route the
                request
                and must store, delete or get the value locally.
            </para>
        </section>

        <section xml:id="Peformance">
            <title>Peformance</title>
            <para>The Repose node will open sockets each time it has to communicate with other Repose nodes to share
                information.
                During times of load this can affect performance and data integrity as when one node cannot communicate
                with another
                it will mark that node damaged and store/create information locally. One way this can happen is if the
                user running
                repose hits their open file limit. Luckily this can be mitigated by increasing the open file limit for
                the user running Repose.
            </para>
        </section>

        <section xml:id="JMX-Reporting">
            <title>JMX Reporting</title>
            <para>Connecting to a Repose instance running the Distributed Datastore via JMX gives access to cache
                statistics implemented by the Ehcache Metrics Library.
            </para>
            <para>MBean: net.sf.ehcache -> Cache >
                PAPI_LOCALrepose-cluster-node:repose-node-id:LocalDatastoreCacheManager
            </para>
        </section>

        <section xml:id="Authentication">
            <title>Authentication</title>
            <para>The authentication components will use the local datastore to cache token, role, and group
                information.
            </para>
        </section>


        <section xml:id="RL">
            <title>Rate Limiting</title>
            <para>Rate limiting can be configured to use any of the three to store rate limiting information for users.
                See the documentation for Rate Limiting to find out how to specify which datastore to use. By default,
                rate limiting will use the distributed datastore if available. If no distributed datastores are
                available,
                then rate limiting will use the local datastore.
            </para>

            <!-- Rate Limiting EXAMPLE goes here.  -->

            <para>With the combination above the Repose instance with the node id 'node1' will launch a Distributed
                Datastore
                service which will listen on port '9999' and the Repose instance with the node id of 'node2' will launch
                it's
                own Distributed Datastore service which will listen on port 7777.
            </para>
        </section>


    </section>
</section>
